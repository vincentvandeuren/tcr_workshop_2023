{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: TCRex results and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data. In addition, this part of the tutorial requires the `scipy`  and `statsmodels` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tcrex_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe. \n",
    "    Ignores meta data information preceded with a '#' sign.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(folder, file), sep = \"\\t\", comment = \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a simple quantitative evaluation of the TCRex prediction results by calculating the identification rate and an enrichment score for a certain epitope. The identification rate describes the percentage of epitope-specific TCRs TCRex found in a repertoire (i.e. the number of TCRs for which a hit was found). To calculate the enrichment score, we perform a one-sided binomial test to assess significant overrepresentation (enrichment) of a particular epitope in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_rate(nr_identified, repertoire_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the percentage of epitope-specific TCRs in a repertoire.\n",
    "    \n",
    "    Args:\n",
    "    - nr_identified: The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    \n",
    "    \"\"\"\n",
    "    return (nr_identified / repertoire_size) * 100\n",
    "\n",
    "def enrichment_analysis(\n",
    "    nr_identified: int, \n",
    "    repertoire_size: int, \n",
    "    threshold: float = 0.001\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the p value of a one sided binomial test.\n",
    "\n",
    "    Args:\n",
    "    - nr_identified:  The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "\n",
    "    \"\"\"\n",
    "    return binom_test(\n",
    "         x = nr_identified, \n",
    "         n = repertoire_size,\n",
    "         p = threshold,\n",
    "         alternative = 'greater'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following sequence of commands, we can calculate the quantitative metrics that we defined previously. That is, for a single epitope. Here, we will illustrate this using the epitope 'FLKEKGGL'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "tcrex_results = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "tcrex_results_epitope = tcrex_results[tcrex_results.epitope == \"FLKEKGGL\"]\n",
    "\n",
    "# Calculate the number of identified epitope-specific TCRs \n",
    "nr_identified = tcrex_results_epitope.shape[0]  \n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size = repertoire.shape[0]\n",
    "\n",
    "p = enrichment_analysis(nr_identified, repertoire_size) # p-value\n",
    "ir = identification_rate(nr_identified, repertoire_size) # identification rate\n",
    "\n",
    "# Calculate the identification metrics\n",
    "print(f\"p value: {p}\")\n",
    "print(f\"Identification rate: {ir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, however, we use multiple TCRex epitope models. Therefore, we should calculate the enrichment score for each epitope individually. The following function does this by looping through every epitope in the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    results: pd.DataFrame, \n",
    "    repertoire_size: int, \n",
    "    threshold: float,\n",
    "    mtc: bool = True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the identification rate and enrichment analysis p value for every epitope in a TCRex results file.\n",
    "    \n",
    "    Args:\n",
    "    - results: Pandas DataFrame containing the TCRex results\n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "    - mtc: p-value correction for multiple tests using Benjamini-Hochberg method for controlling FDR.\n",
    "    \"\"\"\n",
    "    # For every epitope, store the calculated metrics in a dictionary\n",
    "    cols = [\"epitope\", \"pathology\", \"identification_rate\", \"p_value\"]\n",
    "    metrics = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Loop through epitopes\n",
    "    for epitope in results.epitope.unique():\n",
    "        # Retrieve all TCRs specific for the epitope\n",
    "        epitope_data = results[results['epitope'] == epitope]\n",
    "        pathology = epitope_data.pathology.iloc[0]\n",
    "        # Calculate the number of epitope-specific TCRs\n",
    "        nr_identified = epitope_data.shape[0]\n",
    "        # Calculate metrics\n",
    "        ir = identification_rate(nr_identified, repertoire_size)\n",
    "        p = enrichment_analysis(nr_identified, repertoire_size, threshold)\n",
    "        # Add to dataframe\n",
    "        metrics = pd.concat([metrics, pd.DataFrame([[epitope, pathology, ir, p]], columns = cols)])\n",
    "        \n",
    "    if mtc:\n",
    "        # Calculate corrected p-values\n",
    "        p_adj = multipletests(\n",
    "            pvals = metrics.p_value, \n",
    "            method = 'fdr_bh', \n",
    "            is_sorted = False\n",
    "            )[1]\n",
    "        # Add to dataframe\n",
    "        metrics['adjusted_p_value'] = p_adj\n",
    "        \n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function for plotting the epitope distribution of each repertoire as a bar chart with annotated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as mpatches\n",
    "\n",
    "def plot_epitope_distribution(\n",
    "    metrics_df: pd.DataFrame,\n",
    "    name: str,\n",
    "    colordict: dict,\n",
    "    y_value: str = \"identification_rate\",\n",
    "    y_axis: str = \"Identification rate (%)\",\n",
    "    title: str = None,\n",
    "    plot_legend = True\n",
    "    ):\n",
    "    \n",
    "    # Sort data with respect to target attribute\n",
    "    metrics_df = metrics_df.sort_values(by = y_value, ascending = False)\n",
    "\n",
    "    # Map colors to labels\n",
    "    metrics_df[\"colors\"] = metrics_df.pathology.map(colordict)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(dpi = 100)\n",
    "    \n",
    "    # Bar plot\n",
    "    ax.bar(\n",
    "        x = metrics_df.epitope, # x values\n",
    "        height = metrics_df[y_value], # y values\n",
    "        color = metrics_df.colors # color labels\n",
    "        )\n",
    "    \n",
    "    # Plot the names of the epitopes\n",
    "    _ = ax.set_xticklabels(\n",
    "        metrics_df.epitope, \n",
    "        rotation = 90, \n",
    "        fontsize = 8\n",
    "        )\n",
    "\n",
    "    # Axis labels\n",
    "    ax.set_xlabel(\"epitopes\")\n",
    "    ax.set_ylabel(y_axis)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if plot_legend:\n",
    "        # Set up figure legend\n",
    "        handles = [mpatches.Patch(color=colordict[i]) for i in colordict]\n",
    "        labels = [i for i in colordict]\n",
    "        ax.legend(handles, labels, fontsize=6)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"./results/figures/{'.'.join([name,'png'])}\", format = \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put all this together and calculate some the statistics we just defined for every individual epitope for which we screened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_0 = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_0 = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size_day_0 = repertoire_day_0.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_0 = calculate_metrics(\n",
    "    results = results_day_0,\n",
    "    repertoire_size = repertoire_size_day_0,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_0.sort_values(by = 'adjusted_p_value').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_15 = read_tcrex_results('./results/tcrex','P1_15_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_15 = pd.read_csv('./data/examples/P1_15.tsv', sep = '\\t')\n",
    "repertoire_size_day_15 = repertoire_day_15.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_15 = calculate_metrics(\n",
    "    results = results_day_15,\n",
    "    repertoire_size = repertoire_size_day_15,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_15.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the color labels to annotate the epitope distribution bar charts (function defined previously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "# Get colors\n",
    "cmap = cm.get_cmap('tab20') # choose colormap\n",
    "colors = cmap.colors # extract colors\n",
    "\n",
    "pathologies = set(metrics_day_0.pathology).union(set(metrics_day_15.pathology))\n",
    "colorlabels = dict(zip(pathologies, colors[:len(pathologies)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_0, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_0_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_15, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_15_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 15\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the fold change in epitope-specific TCR expression between day 0 and day 15. This will give an indication of which TCRs have expanded (or contracted) between two matched repertoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics_day_0.merge(right = metrics_day_15, on = [\"epitope\", \"pathology\"], how = \"outer\")\n",
    "\n",
    "# We need to make some adjustments to these columns\n",
    "ir_cols = [\"identification_rate_x\", \"identification_rate_y\"]\n",
    "p_cols = [\"p_value_x\", \"p_value_y\", \"adjusted_p_value_x\", \"adjusted_p_value_y\"]\n",
    "\n",
    "# Fill NAs identification rate with 0\n",
    "# Normalize with minimum identification rate to prevent division by zero\n",
    "metrics[ir_cols] = metrics[ir_cols].fillna(0) + metrics[ir_cols].min()\n",
    "# Fill NAs p values rate with 0\n",
    "metrics[p_cols] = metrics[p_cols].fillna(1)\n",
    "\n",
    "# # Calculate fold change (B/A)\n",
    "metrics[\"ir_fold_change\"] = metrics[\"identification_rate_y\"] / metrics[\"identification_rate_x\"]\n",
    "metrics[\"ir_fold_change\"] = np.log2(metrics[\"ir_fold_change\"].astype(float))\n",
    "\n",
    "metrics.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics, \n",
    "    name = \"epitope_fold_change_epitopes\",\n",
    "    colordict = colorlabels,\n",
    "    y_value = \"ir_fold_change\",\n",
    "    y_axis = r\"$\\log_{2}(IR-FC)$\", # IR-FC = identification rate fold change\n",
    "    title = 'Identification rate fold change per epitope (day 0 vs 15)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_grouped = metrics.groupby('pathology').ir_fold_change.sum()\n",
    "pathology_grouped = pathology_grouped.sort_values(ascending = False)\n",
    "\n",
    "fig, ax = plt.subplots(dpi = 150)\n",
    "\n",
    "x = pathology_grouped.index\n",
    "y = pathology_grouped\n",
    "\n",
    "ax.bar(x = x, height = y)\n",
    "ax.axhline(y = 0, c = 'r', ls = '--', lw = .5, label = 'baseline')\n",
    "ax.set_ylabel(r'$\\log_{2}(IR-FC)$')\n",
    "ax.set_xticklabels(x, rotation = 90)\n",
    "ax.set_title('Identification rate fold change per pathology (day 0 vs 15)')\n",
    "ax.set_ylim(-3.5, 3.5)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('./results/figures/ir_fold_change_pathologies.png', format = 'png', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
