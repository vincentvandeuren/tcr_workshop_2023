{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: TCRex results and statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Predicting epitope specificity with TCRex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCRex has a maximum filesize of 50000 sequences, hence larger files need to be split and uploaded separately. For this, you can use the function below, which stores the chunked dataframes in a separate `tcrex_input_chunks` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>junction_aa</th>\n",
       "      <th>v_call</th>\n",
       "      <th>j_call</th>\n",
       "      <th>Total_count</th>\n",
       "      <th>Total_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASSNSDRTYGDNEQFF</td>\n",
       "      <td>TRBV6-2</td>\n",
       "      <td>TRBJ2-1</td>\n",
       "      <td>33422.0</td>\n",
       "      <td>2.171360e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATSSVLTQQETQYF</td>\n",
       "      <td>TRBV24-1</td>\n",
       "      <td>TRBJ2-5</td>\n",
       "      <td>24502.0</td>\n",
       "      <td>1.591845e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASSSRGLANTQYF</td>\n",
       "      <td>TRBV12-3</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>22361.0</td>\n",
       "      <td>1.452749e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSVVGADTYEQYF</td>\n",
       "      <td>TRBV29-1</td>\n",
       "      <td>TRBJ2-7</td>\n",
       "      <td>20930.0</td>\n",
       "      <td>1.359780e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASSLGTALNTEAFF</td>\n",
       "      <td>TRBV7-8</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>20193.0</td>\n",
       "      <td>1.311898e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99711</th>\n",
       "      <td>CASSPRGDPSTDTQYF</td>\n",
       "      <td>TRBV28</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.496797e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>CASSLSGTSYEQFF</td>\n",
       "      <td>TRBV27</td>\n",
       "      <td>TRBJ2-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.496797e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99713</th>\n",
       "      <td>CSATGFSYTEQFF</td>\n",
       "      <td>TRBV20-1</td>\n",
       "      <td>TRBJ2-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.496797e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99714</th>\n",
       "      <td>CASSVGGGQALWGETQYF</td>\n",
       "      <td>TRBV19</td>\n",
       "      <td>TRBJ2-5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.496797e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99715</th>\n",
       "      <td>CATSDFGDHNGELLF</td>\n",
       "      <td>TRBV24-1</td>\n",
       "      <td>TRBJ2-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.496797e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96969 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              junction_aa    v_call   j_call  Total_count  Total_frequency\n",
       "0       CASSNSDRTYGDNEQFF   TRBV6-2  TRBJ2-1      33422.0     2.171360e-02\n",
       "1         CATSSVLTQQETQYF  TRBV24-1  TRBJ2-5      24502.0     1.591845e-02\n",
       "2          CASSSRGLANTQYF  TRBV12-3  TRBJ2-3      22361.0     1.452749e-02\n",
       "3           CSVVGADTYEQYF  TRBV29-1  TRBJ2-7      20930.0     1.359780e-02\n",
       "4         CASSLGTALNTEAFF   TRBV7-8  TRBJ1-1      20193.0     1.311898e-02\n",
       "...                   ...       ...      ...          ...              ...\n",
       "99711    CASSPRGDPSTDTQYF    TRBV28  TRBJ2-3          1.0     6.496797e-07\n",
       "99712      CASSLSGTSYEQFF    TRBV27  TRBJ2-1          1.0     6.496797e-07\n",
       "99713       CSATGFSYTEQFF  TRBV20-1  TRBJ2-1          1.0     6.496797e-07\n",
       "99714  CASSVGGGQALWGETQYF    TRBV19  TRBJ2-5          1.0     6.496797e-07\n",
       "99715     CATSDFGDHNGELLF  TRBV24-1  TRBJ2-2          1.0     6.496797e-07\n",
       "\n",
       "[96969 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def split_file(folder:str, file:str, chunk_size:int=50000) -> None:\n",
    "    # read in the main data\n",
    "    df = pd.read_csv(Path(folder, file), sep=\"\\t\", index_col=[0])\n",
    "    \n",
    "    # create destination path\n",
    "    destination = Path(folder, \"tcrex_input_chunks\")\n",
    "    destination.mkdir(exist_ok=True)\n",
    "\n",
    "    # save chunked data\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        df_chunk = df.iloc[i*chunk_size:(i+1)*chunk_size]\n",
    "        df_chunk.to_csv(Path(destination, f\"{file.rsplit('.', 1)[0]}_{i}.tsv\"), sep=\"\\t\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can chunk our data and create the input files for TCRex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\"P1_0_parsed.tsv\", \"P1_15_parsed.tsv\"]:\n",
    "    split_file(folder=\"data\", file=file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files can be uploaded to the TCRex webserver: https://tcrex.biodatamining.be/\n",
    "\n",
    "Here, you will need to select the epitopes of interest, and TCRex will predict which sequences in your dataset could possibly interact with these epitopes. More information and a detailed manual can be found [here](https://tcrex.biodatamining.be/instructions/). After running these predictions, the result files can be downloaded and place in the `tcrex_results` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data. In addition, this part of the tutorial requires the `scipy`  and `statsmodels` libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Statistical analysis of epitope prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tcrex_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe. \n",
    "    Ignores meta data information preceded with a '#' sign.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(folder, file), sep = \"\\t\", comment = \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a simple quantitative evaluation of the TCRex prediction results by calculating the identification rate and an enrichment score for a certain epitope. The identification rate describes the percentage of epitope-specific TCRs TCRex found in a repertoire (i.e. the number of TCRs for which a hit was found). To calculate the enrichment score, we perform a one-sided binomial test to assess significant overrepresentation (enrichment) of a particular epitope in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_rate(nr_identified, repertoire_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the percentage of epitope-specific TCRs in a repertoire.\n",
    "    \n",
    "    Args:\n",
    "    - nr_identified: The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    \n",
    "    \"\"\"\n",
    "    return (nr_identified / repertoire_size) * 100\n",
    "\n",
    "def enrichment_analysis(\n",
    "    nr_identified: int, \n",
    "    repertoire_size: int, \n",
    "    threshold: float = 0.001\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the p value of a one sided binomial test.\n",
    "\n",
    "    Args:\n",
    "    - nr_identified:  The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "\n",
    "    \"\"\"\n",
    "    return binom_test(\n",
    "         x = nr_identified, \n",
    "         n = repertoire_size,\n",
    "         p = threshold,\n",
    "         alternative = 'greater'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following sequence of commands, we can calculate the quantitative metrics that we defined previously. That is, for a single epitope. Here, we will illustrate this using the epitope 'FLKEKGGL'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "tcrex_results = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "tcrex_results_epitope = tcrex_results[tcrex_results.epitope == \"FLKEKGGL\"]\n",
    "\n",
    "# Calculate the number of identified epitope-specific TCRs \n",
    "nr_identified = tcrex_results_epitope.shape[0]  \n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size = repertoire.shape[0]\n",
    "\n",
    "p = enrichment_analysis(nr_identified, repertoire_size) # p-value\n",
    "ir = identification_rate(nr_identified, repertoire_size) # identification rate\n",
    "\n",
    "# Calculate the identification metrics\n",
    "print(f\"p value: {p}\")\n",
    "print(f\"Identification rate: {ir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, however, we use multiple TCRex epitope models. Therefore, we should calculate the enrichment score for each epitope individually. The following function does this by looping through every epitope in the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    results: pd.DataFrame, \n",
    "    repertoire_size: int, \n",
    "    threshold: float,\n",
    "    mtc: bool = True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the identification rate and enrichment analysis p value for every epitope in a TCRex results file.\n",
    "    \n",
    "    Args:\n",
    "    - results: Pandas DataFrame containing the TCRex results\n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "    - mtc: p-value correction for multiple tests using Benjamini-Hochberg method for controlling FDR.\n",
    "    \"\"\"\n",
    "    # For every epitope, store the calculated metrics in a dictionary\n",
    "    cols = [\"epitope\", \"pathology\", \"identification_rate\", \"p_value\"]\n",
    "    metrics = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Loop through epitopes\n",
    "    for epitope in results.epitope.unique():\n",
    "        # Retrieve all TCRs specific for the epitope\n",
    "        epitope_data = results[results['epitope'] == epitope]\n",
    "        pathology = epitope_data.pathology.iloc[0]\n",
    "        # Calculate the number of epitope-specific TCRs\n",
    "        nr_identified = epitope_data.shape[0]\n",
    "        # Calculate metrics\n",
    "        ir = identification_rate(nr_identified, repertoire_size)\n",
    "        p = enrichment_analysis(nr_identified, repertoire_size, threshold)\n",
    "        # Add to dataframe\n",
    "        metrics = pd.concat([metrics, pd.DataFrame([[epitope, pathology, ir, p]], columns = cols)])\n",
    "        \n",
    "    if mtc:\n",
    "        # Calculate corrected p-values\n",
    "        p_adj = multipletests(\n",
    "            pvals = metrics.p_value, \n",
    "            method = 'fdr_bh', \n",
    "            is_sorted = False\n",
    "            )[1]\n",
    "        # Add to dataframe\n",
    "        metrics['adjusted_p_value'] = p_adj\n",
    "        \n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function for plotting the epitope distribution of each repertoire as a bar chart with annotated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as mpatches\n",
    "\n",
    "def plot_epitope_distribution(\n",
    "    metrics_df: pd.DataFrame,\n",
    "    name: str,\n",
    "    colordict: dict,\n",
    "    y_value: str = \"identification_rate\",\n",
    "    y_axis: str = \"Identification rate (%)\",\n",
    "    title: str = None,\n",
    "    plot_legend = True\n",
    "    ):\n",
    "    \n",
    "    # Sort data with respect to target attribute\n",
    "    metrics_df = metrics_df.sort_values(by = y_value, ascending = False)\n",
    "\n",
    "    # Map colors to labels\n",
    "    metrics_df[\"colors\"] = metrics_df.pathology.map(colordict)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(dpi = 100)\n",
    "    \n",
    "    # Bar plot\n",
    "    ax.bar(\n",
    "        x = metrics_df.epitope, # x values\n",
    "        height = metrics_df[y_value], # y values\n",
    "        color = metrics_df.colors # color labels\n",
    "        )\n",
    "    \n",
    "    # Plot the names of the epitopes\n",
    "    _ = ax.set_xticklabels(\n",
    "        metrics_df.epitope, \n",
    "        rotation = 90, \n",
    "        fontsize = 8\n",
    "        )\n",
    "\n",
    "    # Axis labels\n",
    "    ax.set_xlabel(\"epitopes\")\n",
    "    ax.set_ylabel(y_axis)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if plot_legend:\n",
    "        # Set up figure legend\n",
    "        handles = [mpatches.Patch(color=colordict[i]) for i in colordict]\n",
    "        labels = [i for i in colordict]\n",
    "        ax.legend(handles, labels, fontsize=6)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"./results/figures/{'.'.join([name,'png'])}\", format = \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put all this together and calculate some the statistics we just defined for every individual epitope for which we screened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_0 = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_0 = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size_day_0 = repertoire_day_0.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_0 = calculate_metrics(\n",
    "    results = results_day_0,\n",
    "    repertoire_size = repertoire_size_day_0,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_0.sort_values(by = 'adjusted_p_value').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_15 = read_tcrex_results('./results/tcrex','P1_15_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_15 = pd.read_csv('./data/examples/P1_15.tsv', sep = '\\t')\n",
    "repertoire_size_day_15 = repertoire_day_15.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_15 = calculate_metrics(\n",
    "    results = results_day_15,\n",
    "    repertoire_size = repertoire_size_day_15,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_15.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the color labels to annotate the epitope distribution bar charts (function defined previously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "# Get colors\n",
    "cmap = cm.get_cmap('tab20') # choose colormap\n",
    "colors = cmap.colors # extract colors\n",
    "\n",
    "pathologies = set(metrics_day_0.pathology).union(set(metrics_day_15.pathology))\n",
    "colorlabels = dict(zip(pathologies, colors[:len(pathologies)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_0, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_0_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_15, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_15_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 15\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the fold change in epitope-specific TCR expression between day 0 and day 15. This will give an indication of which TCRs have expanded (or contracted) between two matched repertoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics_day_0.merge(right = metrics_day_15, on = [\"epitope\", \"pathology\"], how = \"outer\")\n",
    "\n",
    "# We need to make some adjustments to these columns\n",
    "ir_cols = [\"identification_rate_x\", \"identification_rate_y\"]\n",
    "p_cols = [\"p_value_x\", \"p_value_y\", \"adjusted_p_value_x\", \"adjusted_p_value_y\"]\n",
    "\n",
    "# Fill NAs identification rate with 0\n",
    "# Normalize with minimum identification rate to prevent division by zero\n",
    "metrics[ir_cols] = metrics[ir_cols].fillna(0) + metrics[ir_cols].min()\n",
    "# Fill NAs p values rate with 0\n",
    "metrics[p_cols] = metrics[p_cols].fillna(1)\n",
    "\n",
    "# # Calculate fold change (B/A)\n",
    "metrics[\"ir_fold_change\"] = metrics[\"identification_rate_y\"] / metrics[\"identification_rate_x\"]\n",
    "metrics[\"ir_fold_change\"] = np.log2(metrics[\"ir_fold_change\"].astype(float))\n",
    "\n",
    "metrics.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics, \n",
    "    name = \"epitope_fold_change_epitopes\",\n",
    "    colordict = colorlabels,\n",
    "    y_value = \"ir_fold_change\",\n",
    "    y_axis = r\"$\\log_{2}(IR-FC)$\", # IR-FC = identification rate fold change\n",
    "    title = 'Identification rate fold change per epitope (day 0 vs 15)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_grouped = metrics.groupby('pathology').ir_fold_change.sum()\n",
    "pathology_grouped = pathology_grouped.sort_values(ascending = False)\n",
    "\n",
    "fig, ax = plt.subplots(dpi = 150)\n",
    "\n",
    "x = pathology_grouped.index\n",
    "y = pathology_grouped\n",
    "\n",
    "ax.bar(x = x, height = y)\n",
    "ax.axhline(y = 0, c = 'r', ls = '--', lw = .5, label = 'baseline')\n",
    "ax.set_ylabel(r'$\\log_{2}(IR-FC)$')\n",
    "ax.set_xticklabels(x, rotation = 90)\n",
    "ax.set_title('Identification rate fold change per pathology (day 0 vs 15)')\n",
    "ax.set_ylim(-3.5, 3.5)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('./results/figures/ir_fold_change_pathologies.png', format = 'png', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
