{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: TCRex results and statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://tcrex.biodatamining.be/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCRex has a maximum filesize of 50000 sequences, hence larger files need to be split and uploaded separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(folder, file):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data/chunked_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m num_chunks \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m chunk_size \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_chunks):\n\u001b[0;32m----> 6\u001b[0m     df[i\u001b[39m*\u001b[39;49mchunk_size:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49mchunk_size]\u001b[39m.\u001b[39;49mto_csv(Path(folder, \u001b[39m\"\u001b[39;49m\u001b[39mchunked_data\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/tcr_workshop/lib/python3.10/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/tcr_workshop/lib/python3.10/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/tcr_workshop/lib/python3.10/site-packages/pandas/io/formats/csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/tcr_workshop/lib/python3.10/site-packages/pandas/io/common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/tcr_workshop/lib/python3.10/site-packages/pandas/io/common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data/chunked_data'"
     ]
    }
   ],
   "source": [
    "folder, file = \"data\", \"P1_0_parsed.tsv\"\n",
    "df = pd.read_csv(Path(folder, file), sep=\"\\t\", index_col=[0])\n",
    "chunk_size = 50000\n",
    "num_chunks = len(df) // chunk_size + 1\n",
    "destination = Path()\n",
    "for i in range(num_chunks):\n",
    "    df[i*chunk_size:(i+1)*chunk_size].to_csv(Path(folder, \"chunked_data\", f\"{file}_{i}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data. In addition, this part of the tutorial requires the `scipy`  and `statsmodels` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tcrex_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe. \n",
    "    Ignores meta data information preceded with a '#' sign.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(folder, file), sep = \"\\t\", comment = \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a simple quantitative evaluation of the TCRex prediction results by calculating the identification rate and an enrichment score for a certain epitope. The identification rate describes the percentage of epitope-specific TCRs TCRex found in a repertoire (i.e. the number of TCRs for which a hit was found). To calculate the enrichment score, we perform a one-sided binomial test to assess significant overrepresentation (enrichment) of a particular epitope in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_rate(nr_identified, repertoire_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the percentage of epitope-specific TCRs in a repertoire.\n",
    "    \n",
    "    Args:\n",
    "    - nr_identified: The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    \n",
    "    \"\"\"\n",
    "    return (nr_identified / repertoire_size) * 100\n",
    "\n",
    "def enrichment_analysis(\n",
    "    nr_identified: int, \n",
    "    repertoire_size: int, \n",
    "    threshold: float = 0.001\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the p value of a one sided binomial test.\n",
    "\n",
    "    Args:\n",
    "    - nr_identified:  The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "\n",
    "    \"\"\"\n",
    "    return binom_test(\n",
    "         x = nr_identified, \n",
    "         n = repertoire_size,\n",
    "         p = threshold,\n",
    "         alternative = 'greater'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following sequence of commands, we can calculate the quantitative metrics that we defined previously. That is, for a single epitope. Here, we will illustrate this using the epitope 'FLKEKGGL'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "tcrex_results = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "tcrex_results_epitope = tcrex_results[tcrex_results.epitope == \"FLKEKGGL\"]\n",
    "\n",
    "# Calculate the number of identified epitope-specific TCRs \n",
    "nr_identified = tcrex_results_epitope.shape[0]  \n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size = repertoire.shape[0]\n",
    "\n",
    "p = enrichment_analysis(nr_identified, repertoire_size) # p-value\n",
    "ir = identification_rate(nr_identified, repertoire_size) # identification rate\n",
    "\n",
    "# Calculate the identification metrics\n",
    "print(f\"p value: {p}\")\n",
    "print(f\"Identification rate: {ir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, however, we use multiple TCRex epitope models. Therefore, we should calculate the enrichment score for each epitope individually. The following function does this by looping through every epitope in the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    results: pd.DataFrame, \n",
    "    repertoire_size: int, \n",
    "    threshold: float,\n",
    "    mtc: bool = True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the identification rate and enrichment analysis p value for every epitope in a TCRex results file.\n",
    "    \n",
    "    Args:\n",
    "    - results: Pandas DataFrame containing the TCRex results\n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "    - mtc: p-value correction for multiple tests using Benjamini-Hochberg method for controlling FDR.\n",
    "    \"\"\"\n",
    "    # For every epitope, store the calculated metrics in a dictionary\n",
    "    cols = [\"epitope\", \"pathology\", \"identification_rate\", \"p_value\"]\n",
    "    metrics = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Loop through epitopes\n",
    "    for epitope in results.epitope.unique():\n",
    "        # Retrieve all TCRs specific for the epitope\n",
    "        epitope_data = results[results['epitope'] == epitope]\n",
    "        pathology = epitope_data.pathology.iloc[0]\n",
    "        # Calculate the number of epitope-specific TCRs\n",
    "        nr_identified = epitope_data.shape[0]\n",
    "        # Calculate metrics\n",
    "        ir = identification_rate(nr_identified, repertoire_size)\n",
    "        p = enrichment_analysis(nr_identified, repertoire_size, threshold)\n",
    "        # Add to dataframe\n",
    "        metrics = pd.concat([metrics, pd.DataFrame([[epitope, pathology, ir, p]], columns = cols)])\n",
    "        \n",
    "    if mtc:\n",
    "        # Calculate corrected p-values\n",
    "        p_adj = multipletests(\n",
    "            pvals = metrics.p_value, \n",
    "            method = 'fdr_bh', \n",
    "            is_sorted = False\n",
    "            )[1]\n",
    "        # Add to dataframe\n",
    "        metrics['adjusted_p_value'] = p_adj\n",
    "        \n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function for plotting the epitope distribution of each repertoire as a bar chart with annotated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as mpatches\n",
    "\n",
    "def plot_epitope_distribution(\n",
    "    metrics_df: pd.DataFrame,\n",
    "    name: str,\n",
    "    colordict: dict,\n",
    "    y_value: str = \"identification_rate\",\n",
    "    y_axis: str = \"Identification rate (%)\",\n",
    "    title: str = None,\n",
    "    plot_legend = True\n",
    "    ):\n",
    "    \n",
    "    # Sort data with respect to target attribute\n",
    "    metrics_df = metrics_df.sort_values(by = y_value, ascending = False)\n",
    "\n",
    "    # Map colors to labels\n",
    "    metrics_df[\"colors\"] = metrics_df.pathology.map(colordict)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(dpi = 100)\n",
    "    \n",
    "    # Bar plot\n",
    "    ax.bar(\n",
    "        x = metrics_df.epitope, # x values\n",
    "        height = metrics_df[y_value], # y values\n",
    "        color = metrics_df.colors # color labels\n",
    "        )\n",
    "    \n",
    "    # Plot the names of the epitopes\n",
    "    _ = ax.set_xticklabels(\n",
    "        metrics_df.epitope, \n",
    "        rotation = 90, \n",
    "        fontsize = 8\n",
    "        )\n",
    "\n",
    "    # Axis labels\n",
    "    ax.set_xlabel(\"epitopes\")\n",
    "    ax.set_ylabel(y_axis)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if plot_legend:\n",
    "        # Set up figure legend\n",
    "        handles = [mpatches.Patch(color=colordict[i]) for i in colordict]\n",
    "        labels = [i for i in colordict]\n",
    "        ax.legend(handles, labels, fontsize=6)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"./results/figures/{'.'.join([name,'png'])}\", format = \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put all this together and calculate some the statistics we just defined for every individual epitope for which we screened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_0 = read_tcrex_results('./results/tcrex','P1_0_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_0 = pd.read_csv('./data/examples/P1_0.tsv', sep = '\\t')\n",
    "repertoire_size_day_0 = repertoire_day_0.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_0 = calculate_metrics(\n",
    "    results = results_day_0,\n",
    "    repertoire_size = repertoire_size_day_0,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_0.sort_values(by = 'adjusted_p_value').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate statistics for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the resuls\n",
    "results_day_15 = read_tcrex_results('./results/tcrex','P1_15_tcrex.tsv')\n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_day_15 = pd.read_csv('./data/examples/P1_15.tsv', sep = '\\t')\n",
    "repertoire_size_day_15 = repertoire_day_15.shape[0]\n",
    "\n",
    "# Calculate metrics for epitopes\n",
    "metrics_day_15 = calculate_metrics(\n",
    "    results = results_day_15,\n",
    "    repertoire_size = repertoire_size_day_15,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "metrics_day_15.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the color labels to annotate the epitope distribution bar charts (function defined previously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "# Get colors\n",
    "cmap = cm.get_cmap('tab20') # choose colormap\n",
    "colors = cmap.colors # extract colors\n",
    "\n",
    "pathologies = set(metrics_day_0.pathology).union(set(metrics_day_15.pathology))\n",
    "colorlabels = dict(zip(pathologies, colors[:len(pathologies)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_0, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_0_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot epitope distribution for P1 at day 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics_day_15, \n",
    "    colordict = colorlabels, \n",
    "    name = 'P1_15_epitope_distribution',\n",
    "    title = \"Identification rate of epitope-specific TCRs at day 15\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the fold change in epitope-specific TCR expression between day 0 and day 15. This will give an indication of which TCRs have expanded (or contracted) between two matched repertoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics_day_0.merge(right = metrics_day_15, on = [\"epitope\", \"pathology\"], how = \"outer\")\n",
    "\n",
    "# We need to make some adjustments to these columns\n",
    "ir_cols = [\"identification_rate_x\", \"identification_rate_y\"]\n",
    "p_cols = [\"p_value_x\", \"p_value_y\", \"adjusted_p_value_x\", \"adjusted_p_value_y\"]\n",
    "\n",
    "# Fill NAs identification rate with 0\n",
    "# Normalize with minimum identification rate to prevent division by zero\n",
    "metrics[ir_cols] = metrics[ir_cols].fillna(0) + metrics[ir_cols].min()\n",
    "# Fill NAs p values rate with 0\n",
    "metrics[p_cols] = metrics[p_cols].fillna(1)\n",
    "\n",
    "# # Calculate fold change (B/A)\n",
    "metrics[\"ir_fold_change\"] = metrics[\"identification_rate_y\"] / metrics[\"identification_rate_x\"]\n",
    "metrics[\"ir_fold_change\"] = np.log2(metrics[\"ir_fold_change\"].astype(float))\n",
    "\n",
    "metrics.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epitope_distribution(\n",
    "    metrics_df = metrics, \n",
    "    name = \"epitope_fold_change_epitopes\",\n",
    "    colordict = colorlabels,\n",
    "    y_value = \"ir_fold_change\",\n",
    "    y_axis = r\"$\\log_{2}(IR-FC)$\", # IR-FC = identification rate fold change\n",
    "    title = 'Identification rate fold change per epitope (day 0 vs 15)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_grouped = metrics.groupby('pathology').ir_fold_change.sum()\n",
    "pathology_grouped = pathology_grouped.sort_values(ascending = False)\n",
    "\n",
    "fig, ax = plt.subplots(dpi = 150)\n",
    "\n",
    "x = pathology_grouped.index\n",
    "y = pathology_grouped\n",
    "\n",
    "ax.bar(x = x, height = y)\n",
    "ax.axhline(y = 0, c = 'r', ls = '--', lw = .5, label = 'baseline')\n",
    "ax.set_ylabel(r'$\\log_{2}(IR-FC)$')\n",
    "ax.set_xticklabels(x, rotation = 90)\n",
    "ax.set_title('Identification rate fold change per pathology (day 0 vs 15)')\n",
    "ax.set_ylim(-3.5, 3.5)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('./results/figures/ir_fold_change_pathologies.png', format = 'png', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
